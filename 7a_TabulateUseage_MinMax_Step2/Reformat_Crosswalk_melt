Copied the name in Census column to the end then did text to col using the semi colon as the delimiter, numbered these
cols 1,2,3... the numbered cols become the cols in the val_vars list

Repeated this step until all semicolon were removed.

crosswalk_excel ='C:\Users\JConno02\OneDrive - Environmental Protection Agency (EPA)\Documents_C_drive\Projects\ESA' \
     '\_ExternalDrive\_CurrentSupportingTables\Usage\ULUT Data Source Summary-crosswalk (draft for review2).xlsx'
sheet_name_2 ='AG Crops (survey status)(+)'

df = pd.read_excel(crosswalk_excel, sheet_name_2, header = 6)

# columns with crops names from census split in excel using text to columns split by ; on Name in Census
val_vars =['CENSUS Crops', 1, 2, 3,4]
# all original cols/ all cols not in val_vars


id_vars_melt =[u'IR-4 Group #', u'Site', u'Parent/Included Sub-Groups ', u'Notes', u'Name in PLUS', u'Name in Census',
u'National CAG', u'Name in iMap', u'Fungicide', u'Herbicide', u'Insecticide', u'Nematicide', u'Growth Regulator',
u'Group in NASS', u'Name in NASS', u'Fungicide.1', u'Herbicide.1', u'Insecticide.1', u'Other', u'Years Surveyed',
 u'Name in PUR', u"CA CAG                           (from 2012 Census of Ag/ or CA Ag Commissioners' report  ?)",
  u'Percent in CA (based on 2012 Census of Ag Acres)', u'Study', u'Notes.1', u'Name in CDL', u'UDL',
  u'Larger group CDL?', u'Larger group UDL?', u'guess', u'COMMENTS']

df_melt_row = pd.melt(df, id_vars=id_vars_melt, value_vars=val_vars, var_name='melt_var',
                          value_name='CENUS_CROP')

df_melt_row.to_csv(r'C:\Users\JConno02\OneDrive - Environmental Protection Agency (EPA)\Documents_C_drive\Projects\ESA
\_ExternalDrive\_CurrentSupportingTables\Usage\crosswalk_melt_2.csv', encoding ='utf-8')
On output table in excel:
    dropped the row index  that was added and melt_var then removed duplicates
    check for blank row in CENSUS_CROP that has a values in the Name in Census col - filled in using these values and trimmed white space
    Removed duplicates again

Using regular expressions and strip to get rid of white space, and all extra characters, NOTE commas CANNOT be removed
from the crop name in the columns that are being joined

# Crops IDed as SEED in CENSUS have the same IR4 name - would SUUM id seed verse crop

When adding additional states
    TODO check if the multi column join on ['State','Parent sub type'] will account for all crops by state

When we receive NASS data
    TOCO Check the col headers to see if the hard coded df col head need to be updated for the parent table specifically the 'Parent sub type']


Read in raw file: df = pd.read_csv(r'D:\qs.census2012.txt', sep ='\t')

column header
['SOURCE_DESC', 'SECTOR_DESC', 'GROUP_DESC', 'COMMODITY_DESC', 'CLASS_DESC', 'PRODN_PRACTICE_DESC',
'UTIL_PRACTICE_DESC', 'STATISTICCAT_DESC', 'UNIT_DESC', 'SHORT_DESC', 'DOMAIN_DESC', 'DOMAINCAT_DESC', 'AGG_LEVEL_DESC',
'STATE_ANSI', 'STATE_FIPS_CODE', 'STATE_ALPHA', 'STATE_NAME', 'ASD_CODE', 'ASD_DESC', 'COUNTY_ANSI', 'COUNTY_CODE',
'COUNTY_NAME', 'REGION_DESC', 'ZIP_5', 'WATERSHED_CODE', 'WATERSHED_DESC', 'CONGR_DISTRICT_CODE', 'COUNTRY_CODE',
'COUNTRY_NAME', 'LOCATION_DESC', 'YEAR', 'FREQ_DESC', 'BEGIN_CODE', 'END_CODE', 'REFERENCE_PERIOD_DESC', 'WEEK_ENDING',
'LOAD_TIME', 'VALUE', 'CV_%']

SECTOR_DESC values: ['CROPS', 'ENVIRONMENTAL', 'DEMOGRAPHICS', 'ECONOMICS', 'ANIMALS & PRODUCTS'])

National filtered to just Sector_DESC == 'CROPS' 1,374,740 - just over limit of excel
Florida Sector_DESC == 'CROPS' 33,452
    first_ten = df[:10]
    rest = df[10:]

fl_df = df[(df['STATE_FIPS_CODE'] == 12) & (df['SECTOR_DESC'] == 'CROPS')]